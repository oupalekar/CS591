{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Whsg1XX_OZs6"
   },
   "source": [
    "# Boilerplate\n",
    "\n",
    "Package installation, loading, and dataloaders. There's also a simple model defined. You can change it your favourite architecture if you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "R1domTvnONqD"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Normalize()\n",
       "  (1): Net(\n",
       "    (linear_relu_stack): Sequential(\n",
       "      (0): Linear(in_features=784, out_features=128, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=128, out_features=64, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=64, out_features=10, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip install tensorboardX\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "# from tensorboardX import SummaryWriter\n",
    "\n",
    "use_cuda = False\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "batch_size = 64\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "\n",
    "## Dataloaders\n",
    "train_dataset = datasets.MNIST('mnist_data/', train=True, download=True, transform=transforms.Compose(\n",
    "    [transforms.ToTensor()]\n",
    "))\n",
    "test_dataset = datasets.MNIST('mnist_data/', train=False, download=True, transform=transforms.Compose(\n",
    "    [transforms.ToTensor()]\n",
    "))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "## Simple NN. You can change this if you want. If you change it, mention the architectural details in your report.\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(784, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 10))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = nn.Flatten()(x)\n",
    "        x = self.linear_relu_stack(x)\n",
    "        return x\n",
    "\n",
    "class Normalize(nn.Module):\n",
    "    def forward(self, x): \n",
    "        return (x - 0.1307)/0.3081\n",
    "\n",
    "# Add the data normalization as a first \"layer\" to the network\n",
    "# this allows us to search for adverserial examples to the real image, rather than\n",
    "# to the normalized image\n",
    "model = nn.Sequential(Normalize(), Net())\n",
    "\n",
    "model = model.to(device)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NCmWfZHTO8Oo"
   },
   "source": [
    "# Implement the Attacks\n",
    "\n",
    "Functions are given a simple useful signature that you can start with. Feel free to extend the signature as you see fit.\n",
    "\n",
    "You may find it useful to create a 'batched' version of PGD that you can use to create the adversarial attack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "EZjvA49yONqP"
   },
   "outputs": [],
   "source": [
    "# The last argument 'targeted' can be used to toggle between a targeted and untargeted attack.\n",
    "def fgsm(model, x, label, eps):\n",
    "    #TODO: implement this as an intermediate step of PGD\n",
    "    # Notes: put the model in eval() mode for this function\n",
    "    model.eval()\n",
    "    # x.requires_grad_()\n",
    "    output = model(x)\n",
    "    loss = F.cross_entropy(output, label)\n",
    "\n",
    "    grad = torch.autograd.grad(\n",
    "                loss, x, retain_graph=False, create_graph=False\n",
    "            )[0]\n",
    "\n",
    "    x_adv = x.detach() + eps * torch.sign(grad)\n",
    "    return x_adv\n",
    "\n",
    "\n",
    "\n",
    "def pgd_untargeted(model, x, y, k, eps, eps_step):\n",
    "    #TODO: implement this \n",
    "    # Notes: put the model in eval() mode for this function\n",
    "    \n",
    "    model.eval()\n",
    "    adv_images = x.clone().detach()\n",
    "    for _ in range(k):\n",
    "        adv_images.requires_grad = True\n",
    "        x_adv = fgsm(model, adv_images, y, eps_step)\n",
    "        delta = torch.clamp(x_adv - x, min=-eps, max=eps)\n",
    "        adv_images = torch.clamp(x + delta, min = 0, max = 1)\n",
    "    \n",
    "    return adv_images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Mja_AB4RykO"
   },
   "source": [
    "# Implement Adversarial Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "V-sw8yKYONqQ"
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, num_epochs, enable_defense=True, attack='pgd', eps=0.1):\n",
    "    # TODO: implement this function that trains a given model on the MNIST dataset.\n",
    "    # this is a general-purpose function for both standard training and adversarial training.\n",
    "    # (toggle enable_defense parameter to switch between training schemes)\n",
    "    model.train()\n",
    "\n",
    "    lr = 1e-2\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "    for epoch in range(num_epochs):\n",
    "        for index, (images, labels) in enumerate(train_loader):\n",
    "            logits = model(images)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss = F.cross_entropy(logits, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print(f'Epoch [{epoch}/{num_epochs}] Loss = {loss.item():.3f}')\n",
    "\n",
    "    if enable_defense:\n",
    "            for epoch in range(num_epochs):\n",
    "                for index, (images, labels) in enumerate(train_loader):\n",
    "                    adversary_images = pgd_untargeted(model, images, labels, 10,  eps, 0.01)\n",
    "                    model.train()\n",
    "                    optimizer.zero_grad()\n",
    "                    logits = model(adversary_images)\n",
    "                    loss = F.cross_entropy(logits, labels)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    \n",
    "                print(f'Epoch [{epoch}/{num_epochs}] Loss = {loss.item():.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_model_on_attacks(model, attack='pgd', eps=0.1):\n",
    "    # TODO: implement this function to test the robust accuracy of the given model\n",
    "    # use pgd_untargeted() within this function\n",
    "    correct = 0\n",
    "    model.eval()\n",
    "    for j, (images, labels) in enumerate(test_loader):\n",
    "        images, labels = images, labels\n",
    "        adversarial_images = pgd_untargeted(model, images, labels, 20, eps, 0.01)        \n",
    "        logits = model(adversarial_images)\n",
    "        _, preds = torch.max(logits, 1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        # print('Batch [{}/{}]'.format(j+1, len(test_loader)))\n",
    "    model.train()\n",
    "    print('Accuracy = {}%'.format(float(correct) * 100 / 10000))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZPMdfEhtR3zm"
   },
   "source": [
    "# Study Accuracy, Quality, etc.\n",
    "\n",
    "Compare the various results and report your observations on the submission."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## train the original model\n",
    "model = nn.Sequential(Normalize(), Net())\n",
    "model = model.to(device)\n",
    "model.train()\n",
    "\n",
    "train_model(model, train_loader, 30, False)\n",
    "torch.save(model.state_dict(), 'standard-weights.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "adv_images = []\n",
    "epss= [0.05, 0.1, 0.15, 0.2]\n",
    "for eps in epss:\n",
    "    for j, (images, labels) in enumerate(test_loader):\n",
    "        images, labels = images, labels\n",
    "        adv_image = pgd_untargeted(model, images, labels, 20, eps, 0.01)  \n",
    "        break\n",
    "    adv_images.append(adv_image[0])\n",
    "print(len(adv_images))\n",
    "# sample_img , sample_lbl = temp_train_dataset[3]\n",
    "figure = plt.figure()\n",
    "cols, rows = 4, 1\n",
    "figure.add_subplot(rows, cols, 1)\n",
    "for i in range(1, cols * rows + 1):\n",
    "    plt.axis('off')\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "\n",
    "    plt.title(f'eps = {epss[i - 1]}')\n",
    "    plt.imshow(adv_images[i - 1].squeeze(), cmap=\"gray\")\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 98.18%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "model.eval()\n",
    "for j, (images, labels) in enumerate(test_loader):\n",
    "  images, labels = images, labels\n",
    "  logits = model(images)\n",
    "  _, preds = torch.max(logits, 1)\n",
    "  correct += (preds == labels).sum().item()\n",
    "  # print('Batch [{}/{}]'.format(j+1, len(test_loader)))\n",
    "model.train()\n",
    "print('Accuracy = {}%'.format(float(correct) * 100 / 10000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy on Adversarial Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 72.81%\n",
      "Accuracy = 14.52%\n",
      "Accuracy = 2.86%\n",
      "Accuracy = 1.11%\n"
     ]
    }
   ],
   "source": [
    "## PGD attack\n",
    "model = nn.Sequential(Normalize(), Net())\n",
    "model.load_state_dict(torch.load('standard-weights.pt', weights_only=True))\n",
    "\n",
    "for eps in [0.05, 0.1, 0.15, 0.2]:\n",
    "    test_model_on_attacks(model, attack='pgd', eps=eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Robust Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 55.875%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "eps = 0.1\n",
    "model.eval()\n",
    "for j, (images, labels) in enumerate(test_loader):\n",
    "  images, labels = images, labels\n",
    "  adv_images = pgd_untargeted(model, images, labels, 20, eps, 0.01)  \n",
    "  logits = model(images)\n",
    "  adv_logits = model(adv_images)\n",
    "  _, preds = torch.max(logits, 1)\n",
    "  _, adv_preds = torch.max(adv_logits, 1)\n",
    "  correct += (preds == labels).sum().item()\n",
    "  correct += (adv_preds == labels).sum().item()\n",
    "  # print('Batch [{}/{}]'.format(j+1, len(test_loader)))\n",
    "model.train()\n",
    "print('Accuracy = {}%'.format(float(correct) * 100 / 20000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarial Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ufD-ccTFR8R2"
   },
   "outputs": [],
   "source": [
    "## PGD based adversarial training\n",
    "adv_train_model = nn.Sequential(Normalize(), Net())\n",
    "eps = 0.1\n",
    "train_model(adv_train_model, train_loader, 20, True, 'pgd', eps)\n",
    "torch.save(adv_train_model.state_dict(), f'weights_AT_{eps}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = nn.Sequential(Normalize(), Net())\n",
    "model.load_state_dict(torch.load('weights_AT_0.1.pt', weights_only=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 98.05%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "model.eval()\n",
    "for j, (images, labels) in enumerate(test_loader):\n",
    "  images, labels = images, labels\n",
    "  logits = model(images)\n",
    "  _, preds = torch.max(logits, 1)\n",
    "  correct += (preds == labels).sum().item()\n",
    "  # print('Batch [{}/{}]'.format(j+1, len(test_loader)))\n",
    "model.train()\n",
    "print('Accuracy = {}%'.format(float(correct) * 100 / 10000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy on Adversarial Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 95.6%\n",
      "Accuracy = 89.46%\n",
      "Accuracy = 75.76%\n",
      "Accuracy = 52.83%\n"
     ]
    }
   ],
   "source": [
    "## PGD attack\n",
    "for eps in [0.05, 0.1, 0.15, 0.2]:\n",
    "    test_model_on_attacks(model, attack='pgd', eps=eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Robust Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 93.755%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "eps = 0.1\n",
    "model.eval()\n",
    "for j, (images, labels) in enumerate(test_loader):\n",
    "  images, labels = images, labels\n",
    "  adv_images = pgd_untargeted(model, images, labels, 20, eps, 0.01)  \n",
    "  logits = model(images)\n",
    "  adv_logits = model(adv_images)\n",
    "  _, preds = torch.max(logits, 1)\n",
    "  _, adv_preds = torch.max(adv_logits, 1)\n",
    "  correct += (preds == labels).sum().item()\n",
    "  correct += (adv_preds == labels).sum().item()\n",
    "  # print('Batch [{}/{}]'.format(j+1, len(test_loader)))\n",
    "model.train()\n",
    "print('Accuracy = {}%'.format(float(correct) * 100 / 20000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adv_model = nn.Sequential(Normalize(), Net())\n",
    "adv_model.load_state_dict(torch.load('weights_AT_0.1.pt', weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 92.15%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "eps = 0.1\n",
    "model.eval()\n",
    "for j, (images, labels) in enumerate(test_loader):\n",
    "  images, labels = images, labels\n",
    "  images.requires_grad = True\n",
    "  adv_images = fgsm(model, images, labels, 0.1) \n",
    "  logits = model(images)\n",
    "  adv_logits = model(adv_images)\n",
    "  _, preds = torch.max(logits, 1)\n",
    "  _, adv_preds = torch.max(adv_logits, 1)\n",
    "  correct += (preds == labels).sum().item()\n",
    "  correct += (adv_preds == labels).sum().item()\n",
    "  # print('Batch [{}/{}]'.format(j+1, len(test_loader)))\n",
    "model.train()\n",
    "print('Accuracy = {}%'.format(float(correct) * 100 / 20000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchattacks.attacks.tpgd import TPGD\n",
    "from torchattacks.attacks.gn import GN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 97.93%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "eps = 0.1\n",
    "model.eval()\n",
    "for j, (images, labels) in enumerate(test_loader):\n",
    "  attack = TPGD(adv_model,eps=8/255, alpha=2/255, steps=10)\n",
    "  adv_images = attack(images)\n",
    "  logits = adv_model(images)\n",
    "  adv_logits = adv_model(adv_images)\n",
    "  _, preds = torch.max(logits, 1)\n",
    "  _, adv_preds = torch.max(adv_logits, 1)\n",
    "  correct += (preds == labels).sum().item()\n",
    "  correct += (adv_preds == labels).sum().item()\n",
    "  # print('Batch [{}/{}]'.format(j+1, len(test_loader)))\n",
    "model.train()\n",
    "print('Accuracy = {}%'.format(float(correct) * 100 / 20000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 98.105%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "eps = 0.1\n",
    "adv_model.eval()\n",
    "for j, (images, labels) in enumerate(test_loader):\n",
    "  attack = GN(adv_model)\n",
    "  adv_images = attack(images)\n",
    "  logits = adv_model(images)\n",
    "  adv_logits = adv_model(adv_images)\n",
    "  _, preds = torch.max(logits, 1)\n",
    "  _, adv_preds = torch.max(adv_logits, 1)\n",
    "  correct += (preds == labels).sum().item()\n",
    "  correct += (adv_preds == labels).sum().item()\n",
    "  # print('Batch [{}/{}]'.format(j+1, len(test_loader)))\n",
    "model.train()\n",
    "print('Accuracy = {}%'.format(float(correct) * 100 / 20000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
