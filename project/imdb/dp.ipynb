{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, \"/home/oru2/project/project\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import time\n",
    "# import matplotlib.pyplot as plt\n",
    "import attacks\n",
    "from privacy_accountant import PrivacyAccountant\n",
    "from tqdm import tqdm\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from collections import Counter\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"../imdb_data/IMDB Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/oru2/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/oru2/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/oru2/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 40000, Test samples: 10000\n"
     ]
    }
   ],
   "source": [
    "#credit: https://www.kaggle.com/code/m0hammadjavad/imdb-sentiment-classifier-pytorch/notebook\n",
    "import nltk\n",
    "import os\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    \n",
    "    filtered_tokens = [word for word in tokens if word.isalpha() and word not in stop_words]\n",
    "\n",
    "    doc = nlp(' '.join(filtered_tokens))\n",
    "    \n",
    "    lemmetized_tokens = [token.lemma_ for token in doc]\n",
    "    \n",
    "    return ' '.join(lemmetized_tokens)\n",
    "\n",
    "if os.path.exists(\"../imdb_data/IMDB Dataset_with_cleaned_reviews.csv\"):\n",
    "    data = pd.read_csv(\"../imdb_data/IMDB Dataset_with_cleaned_reviews.csv\")\n",
    "else:  \n",
    "    data[\"cleaned_reviews\"] = data[\"review\"].apply(preprocess_text)\n",
    "    data.to_csv(\"../imdb_data/IMDB Dataset_with_cleaned_reviews.csv\")\n",
    "\n",
    "data[\"sentiment\"] = data[\"sentiment\"].map({\"positive\": 1, \"negative\": 0})\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[\"cleaned_reviews\"], data[\"sentiment\"], test_size=0.2, random_state=42)\n",
    "print(f'Training samples: {len(X_train)}, Test samples: {len(X_test)}')\n",
    "\n",
    "\n",
    "# Create a vocabulary based on the training data\n",
    "def build_vocab(texts):\n",
    "    \n",
    "    # this makes a dict with unique words and their count as the value\n",
    "    # although this is not going to be used directly, it only gives us unique words without repeatition\n",
    "    counter = Counter()\n",
    "    for text in texts:\n",
    "        counter.update(text.split())\n",
    "        \n",
    "    # this makes a dict of unique words and their index as the value\n",
    "    vocab = {word: idx for idx, (word, _) in enumerate(counter.items(), 1)}  # Reserve index 0 for padding\n",
    "    \n",
    "    # this is a convention which is going to be used to convert batches to a fixed size\n",
    "    vocab['<PAD>'] = 0\n",
    "    \n",
    "    return vocab\n",
    "\n",
    "# Build the vocabulary\n",
    "vocab = build_vocab(X_train)\n",
    "\n",
    "# Encode text sequences into integer sequences\n",
    "def encode_text(text, vocab, max_length=200):\n",
    "    tokens = text.split()\n",
    "    encoded = [vocab.get(token, 0) for token in tokens]  # 0 for unknown tokens\n",
    "    if len(encoded) < max_length:\n",
    "        encoded += [vocab['<PAD>']] * (max_length - len(encoded))  # Padding\n",
    "    return encoded[:max_length]  # Truncate to max_length\n",
    "\n",
    "# Encode all reviews\n",
    "X_train_encoded = torch.tensor([encode_text(text, vocab) for text in X_train])\n",
    "X_test_encoded = torch.tensor([encode_text(text, vocab) for text in X_test])\n",
    "y_train_tensor = torch.nn.functional.one_hot(torch.tensor(y_train.values))\n",
    "y_test_tensor =  torch.nn.functional.one_hot(torch.tensor(y_test.values))\n",
    "\n",
    "# Create DataLoader for batching\n",
    "train_data = TensorDataset(X_train_encoded, y_train_tensor)\n",
    "test_data = TensorDataset(X_test_encoded, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=500, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=500, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f3e5de76910>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_cuda = True\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "batch_size = 500\n",
    "\n",
    "MAX_GRAD_NORM = 1.2\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import SentimentModel\n",
    "vocab_size = len(vocab)\n",
    "embed_size = 100\n",
    "hidden_size = 128\n",
    "output_size = 2  # Binary classification (positive/negative)\n",
    "num_layers = 2\n",
    "fc_model = SentimentModel(vocab_size, embed_size, hidden_size, output_size, num_layers).to(device)\n",
    "num_epochs = 20\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from opacus import PrivacyEngine\n",
    "model.remove_hooks()\n",
    "privacy_engine = PrivacyEngine(secure_mode=False)\n",
    "optimizer = torch.optim.Adam(fc_model.parameters(), lr=1e-2)\n",
    "model, optimizer, train_loader = privacy_engine.make_private_with_epsilon(\n",
    "    module=fc_model,\n",
    "    optimizer=optimizer,\n",
    "    data_loader=train_loader,\n",
    "    max_grad_norm=1.5,\n",
    "    target_delta=1e-5,\n",
    "    target_epsilon=5,\n",
    "    epochs=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(preds, labels):\n",
    "    return (preds == labels).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, train_loader, num_epochs):\n",
    "    # TODO: implement this function that trains a given model on the MNIST dataset.\n",
    "    # this is a general-purpose function for both standard training and adversarial training.\n",
    "    # (toggle enable_defense parameter to switch between training schemes)\n",
    "    model.train()\n",
    "    noise_multiplier = 1.1\n",
    "    # epsilons_clean = []\n",
    "    lr = 1e-2\n",
    "    accs = []\n",
    "    losses = []\n",
    "    running_loss = 0.0\n",
    "    # optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        for index, (inputs, labels) in enumerate(train_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            logits = model(inputs)\n",
    "            loss = nn.CrossEntropyLoss()(logits, labels.float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            losses.append(loss.item())\n",
    "                \n",
    "        printstr = (\n",
    "        f\"\\t Epoch {epoch}. Loss: {np.mean(losses):.6f}\"\n",
    "        )\n",
    "        if privacy_engine:\n",
    "            epsilon = privacy_engine.get_epsilon(1e-5)\n",
    "            printstr += f\" | (ε = {epsilon:.2f}, δ = {1e-5})\"\n",
    "\n",
    "        print(printstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [00:42<13:31, 42.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Epoch 0. Loss: 0.693258 | (ε = 1.76, δ = 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [01:25<12:48, 42.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Epoch 1. Loss: 0.693243 | (ε = 2.10, δ = 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [02:07<12:00, 42.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Epoch 2. Loss: 0.693093 | (ε = 2.36, δ = 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [02:49<11:17, 42.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Epoch 3. Loss: 0.692927 | (ε = 2.59, δ = 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [03:32<10:37, 42.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Epoch 4. Loss: 0.692748 | (ε = 2.79, δ = 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [04:14<09:54, 42.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Epoch 5. Loss: 0.692489 | (ε = 2.98, δ = 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7/20 [04:57<09:13, 42.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Epoch 6. Loss: 0.692177 | (ε = 3.16, δ = 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [05:40<08:31, 42.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Epoch 7. Loss: 0.692089 | (ε = 3.34, δ = 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [06:22<07:47, 42.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Epoch 8. Loss: 0.691949 | (ε = 3.50, δ = 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [07:04<07:04, 42.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Epoch 9. Loss: 0.692396 | (ε = 3.66, δ = 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11/20 [07:47<06:21, 42.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Epoch 10. Loss: 0.692267 | (ε = 3.81, δ = 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 12/20 [08:28<05:37, 42.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Epoch 11. Loss: 0.690669 | (ε = 3.95, δ = 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 13/20 [09:11<04:56, 42.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Epoch 12. Loss: 0.689071 | (ε = 4.10, δ = 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 14/20 [09:54<04:14, 42.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Epoch 13. Loss: 0.687326 | (ε = 4.23, δ = 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 15/20 [10:37<03:33, 42.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Epoch 14. Loss: 0.685499 | (ε = 4.37, δ = 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 16/20 [11:20<02:51, 42.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Epoch 15. Loss: 0.684248 | (ε = 4.50, δ = 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 17/20 [12:03<02:08, 42.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Epoch 16. Loss: 0.683555 | (ε = 4.63, δ = 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 18/20 [12:46<01:25, 42.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Epoch 17. Loss: 0.682898 | (ε = 4.75, δ = 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 19/20 [13:29<00:43, 43.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Epoch 18. Loss: 0.682296 | (ε = 4.88, δ = 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [14:13<00:00, 42.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Epoch 19. Loss: 0.681980 | (ε = 5.00, δ = 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_model(model, optimizer, train_loader, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'models/dp.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1187474/4042864840.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  fc_model = torch.load(f=\"models/dp.pt\")\n"
     ]
    }
   ],
   "source": [
    "fc_model = torch.load(f=\"models/dp.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 60.29%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "model.eval()\n",
    "for j, (inputs, labels) in enumerate(test_loader):\n",
    "  inputs = inputs.to(device)\n",
    "  labels = labels.to(device)\n",
    "  \n",
    "  logits = model(inputs)\n",
    "\n",
    "  prediction = torch.argmax(logits, 1)\n",
    "  correct += (prediction == torch.argmax(labels, dim=1)).sum().item()\n",
    "  # print('Batch [{}/{}]'.format(j+1, len(test_loader)))\n",
    "model.train()\n",
    "print('Accuracy = {}%'.format(float(correct) * 100 / 10000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oru2/project/env/lib/python3.10/site-packages/torch/nn/modules/module.py:1827: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 53.73%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "eps = 0.1\n",
    "# attack = attacks.LSTMPGD(fc_model, epsilon=eps, num_steps=10, embedding_layer=fc_model.embedding)\n",
    "torch.backends.cudnn.enabled = False\n",
    "for j, (inputs, labels) in enumerate(test_loader):\n",
    "  inputs = inputs.to(device)\n",
    "  labels = labels.to(device)\n",
    "  embeddings = model.embedding(inputs)\n",
    "  adv_inputs = attacks.perturb_data(fc_model, embeddings, labels, epsilon = eps)\n",
    "  # print(adv_images)\n",
    "  logits = model(inputs)\n",
    "\n",
    "  adv_logits = model.lstm(adv_inputs)[0][:, -1, :]\n",
    "  adv_logits = torch.sigmoid(fc_model.fc(adv_logits))\n",
    "  # adv_logits = fc_model(adv_images)\n",
    "\n",
    "  prediction = torch.argmax(logits, 1)\n",
    "\n",
    "  adv_prediction = torch.argmax(adv_logits, 1)\n",
    "\n",
    "\n",
    "  correct += (prediction == torch.argmax(labels)).sum().item()\n",
    "  correct += (adv_prediction == torch.argmax(labels)).sum().item()\n",
    "  # print('Batch [{}/{}]'.format(j+1, len(test_loader)))\n",
    "print('Accuracy = {}%'.format(float(correct) * 100 / 20000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from art.attacks.inference.membership_inference import MembershipInferenceBlackBox\n",
    "from art.estimators.classification import PyTorchClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import SentimentModelNoEmbed\n",
    "no_embed_model = SentimentModelNoEmbed(embed_size, hidden_size, output_size, num_layers).to(device)\n",
    "\n",
    "optimizer_ = torch.optim.Adam(no_embed_model.parameters(), lr=1e-2)\n",
    "model, optimizer, train_loader = privacy_engine.make_private_with_epsilon(\n",
    "    module=no_embed_model,\n",
    "    optimizer=optimizer_,\n",
    "    data_loader=train_loader,\n",
    "    max_grad_norm=1.5,\n",
    "    target_delta=1e-5,\n",
    "    target_epsilon=5,\n",
    "    epochs=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['_module.lstm.weight_ih_l0', '_module.lstm.bias_ih_l0', '_module.lstm.weight_hh_l0', '_module.lstm.bias_hh_l0', '_module.lstm.weight_ih_l1', '_module.lstm.bias_ih_l1', '_module.lstm.weight_hh_l1', '_module.lstm.bias_hh_l1', '_module.lstm.l0.ih.weight', '_module.lstm.l0.ih.bias', '_module.lstm.l0.hh.weight', '_module.lstm.l0.hh.bias', '_module.lstm.l1.ih.weight', '_module.lstm.l1.ih.bias', '_module.lstm.l1.hh.weight', '_module.lstm.l1.hh.bias', '_module.fc.weight', '_module.fc.bias'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(model.state_dict().keys())\n",
    "state_dict = {k: fc_model.state_dict()[k] for k in filter(lambda x: not 'embedding' in x, fc_model.state_dict())}\n",
    "no_embed_model.load_state_dict(state_dict, strict=False) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "\n",
    "# Wrap the PyTorch model in ART's PyTorchClassifier\n",
    "art_classifier = PyTorchClassifier(\n",
    "    model=no_embed_model,\n",
    "    loss=criterion,\n",
    "    optimizer=optimizer_,\n",
    "    input_shape=(200,),\n",
    "    nb_classes=2\n",
    ")\n",
    "attack_train_size = 10000\n",
    "attack_test_size = 5000\n",
    "\n",
    "x_train = train_data.tensors[0]\n",
    "y_train = train_data.tensors[1].detach().numpy()\n",
    "\n",
    "\n",
    "x_test = test_data.tensors[0]\n",
    "y_test = test_data.tensors[1].detach().numpy()\n",
    "\n",
    "x_train = nn.Embedding(vocab_size, embed_size)(x_train).detach().numpy()\n",
    "x_test = nn.Embedding(vocab_size, embed_size)(x_test).detach().numpy()\n",
    "\n",
    "attack = MembershipInferenceBlackBox(estimator=art_classifier, attack_model_type=\"nn\")\n",
    "attack.fit(x_train[:attack_train_size], y_train[:attack_train_size], x_test[:attack_test_size], y_test[:attack_test_size])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Members Accuracy: 0.7970\n",
      "Non Members Accuracy 0.7988\n",
      "Attack Accuracy 0.7973\n"
     ]
    }
   ],
   "source": [
    "mlp_inferred_train_bb = attack.infer(x_train[attack_train_size:], y_train[attack_train_size:])\n",
    "mlp_inferred_test_bb = attack.infer(x_test[attack_test_size:], y_test[attack_test_size:])\n",
    "\n",
    "# check accuracy\n",
    "mlp_train_acc_bb = np.sum(mlp_inferred_train_bb) / len(mlp_inferred_train_bb)\n",
    "mlp_test_acc_bb = 1 - (np.sum(mlp_inferred_test_bb) / len(mlp_inferred_test_bb))\n",
    "mlp_acc_bb = (mlp_train_acc_bb * len(mlp_inferred_train_bb) + mlp_test_acc_bb * len(mlp_inferred_test_bb)) / (len(mlp_inferred_train_bb) + len(mlp_inferred_test_bb))\n",
    "\n",
    "print(f\"Members Accuracy: {mlp_train_acc_bb:.4f}\")\n",
    "print(f\"Non Members Accuracy {mlp_test_acc_bb:.4f}\")\n",
    "print(f\"Attack Accuracy {mlp_acc_bb:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "privacy_engine.get_epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.2008e+00,  1.5396e+00,  1.4179e+00,  ...,  5.5041e-01,\n",
       "          -4.3193e-01, -2.4356e-01],\n",
       "         [ 2.2167e-01, -2.7137e-01,  2.1014e-01,  ..., -1.0977e+00,\n",
       "          -7.6189e-01, -1.6361e+00],\n",
       "         [-8.4064e-03, -9.4465e-02, -4.9066e-01,  ...,  7.0453e-01,\n",
       "           6.9287e-01, -1.4205e+00],\n",
       "         ...,\n",
       "         [ 7.2725e-02,  7.8139e-01,  6.2422e-01,  ..., -2.6550e+00,\n",
       "           3.7356e-01, -4.9829e-01],\n",
       "         [ 7.2725e-02,  7.8139e-01,  6.2422e-01,  ..., -2.6550e+00,\n",
       "           3.7356e-01, -4.9829e-01],\n",
       "         [ 7.2725e-02,  7.8139e-01,  6.2422e-01,  ..., -2.6550e+00,\n",
       "           3.7356e-01, -4.9829e-01]],\n",
       "\n",
       "        [[ 1.4441e+00,  1.1737e+00, -1.4373e+00,  ..., -1.0749e+00,\n",
       "          -1.6892e+00, -1.3481e+00],\n",
       "         [ 6.1772e-01, -6.9171e-01,  1.2618e+00,  ...,  1.9872e+00,\n",
       "          -3.9961e-01, -5.8853e-01],\n",
       "         [-1.2826e-01, -4.8372e-01, -5.2664e-01,  ..., -5.0066e-01,\n",
       "          -1.2826e-01, -1.1033e+00],\n",
       "         ...,\n",
       "         [ 7.2725e-02,  7.8139e-01,  6.2422e-01,  ..., -2.6550e+00,\n",
       "           3.7356e-01, -4.9829e-01],\n",
       "         [ 7.2725e-02,  7.8139e-01,  6.2422e-01,  ..., -2.6550e+00,\n",
       "           3.7356e-01, -4.9829e-01],\n",
       "         [ 7.2725e-02,  7.8139e-01,  6.2422e-01,  ..., -2.6550e+00,\n",
       "           3.7356e-01, -4.9829e-01]],\n",
       "\n",
       "        [[ 3.5313e-01, -6.4696e-02, -1.0170e+00,  ..., -4.6488e-01,\n",
       "          -5.7841e-02,  1.0938e+00],\n",
       "         [-1.1779e+00, -1.1605e+00,  2.1275e-01,  ...,  5.9294e-01,\n",
       "           1.0522e+00,  1.0124e+00],\n",
       "         [ 6.7079e-01, -5.0549e-01, -2.4617e-01,  ...,  7.1658e-01,\n",
       "           1.3217e+00, -9.9319e-01],\n",
       "         ...,\n",
       "         [ 7.2725e-02,  7.8139e-01,  6.2422e-01,  ..., -2.6550e+00,\n",
       "           3.7356e-01, -4.9829e-01],\n",
       "         [ 7.2725e-02,  7.8139e-01,  6.2422e-01,  ..., -2.6550e+00,\n",
       "           3.7356e-01, -4.9829e-01],\n",
       "         [ 7.2725e-02,  7.8139e-01,  6.2422e-01,  ..., -2.6550e+00,\n",
       "           3.7356e-01, -4.9829e-01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-4.4379e-01,  6.4212e-02, -5.5830e-01,  ..., -1.7309e-01,\n",
       "          -6.6929e-01,  4.9953e-01],\n",
       "         [-3.8706e-02,  2.0035e-01, -4.2953e-01,  ...,  9.0817e-01,\n",
       "           2.6609e+00, -8.8467e-03],\n",
       "         [-1.0066e-01,  6.7764e-01,  1.3813e+00,  ...,  6.0390e-01,\n",
       "          -1.0233e-01,  4.5856e-02],\n",
       "         ...,\n",
       "         [ 7.2725e-02,  7.8139e-01,  6.2422e-01,  ..., -2.6550e+00,\n",
       "           3.7356e-01, -4.9829e-01],\n",
       "         [ 7.2725e-02,  7.8139e-01,  6.2422e-01,  ..., -2.6550e+00,\n",
       "           3.7356e-01, -4.9829e-01],\n",
       "         [ 7.2725e-02,  7.8139e-01,  6.2422e-01,  ..., -2.6550e+00,\n",
       "           3.7356e-01, -4.9829e-01]],\n",
       "\n",
       "        [[ 4.2877e-01,  6.3098e-01,  8.5166e-01,  ..., -2.6516e-03,\n",
       "           3.6147e-01, -1.2036e-01],\n",
       "         [-5.8604e-01,  5.1376e-01,  7.6174e-01,  ...,  1.1001e-01,\n",
       "           5.1262e-01,  5.7579e-01],\n",
       "         [ 1.4745e+00, -7.0118e-01, -3.9411e-01,  ..., -7.4156e-01,\n",
       "           5.4309e-01, -1.1444e+00],\n",
       "         ...,\n",
       "         [ 7.2725e-02,  7.8139e-01,  6.2422e-01,  ..., -2.6550e+00,\n",
       "           3.7356e-01, -4.9829e-01],\n",
       "         [ 7.2725e-02,  7.8139e-01,  6.2422e-01,  ..., -2.6550e+00,\n",
       "           3.7356e-01, -4.9829e-01],\n",
       "         [ 7.2725e-02,  7.8139e-01,  6.2422e-01,  ..., -2.6550e+00,\n",
       "           3.7356e-01, -4.9829e-01]],\n",
       "\n",
       "        [[-1.6000e+00,  3.5574e-01,  4.0358e-01,  ...,  8.7753e-01,\n",
       "           1.2214e+00,  1.5603e+00],\n",
       "         [-1.2826e-01, -4.8372e-01, -5.2664e-01,  ..., -5.0066e-01,\n",
       "          -1.2826e-01, -1.1033e+00],\n",
       "         [ 7.4236e-01,  2.9955e-01,  8.0509e-01,  ...,  1.3728e+00,\n",
       "           2.5560e-01,  5.1105e-01],\n",
       "         ...,\n",
       "         [ 7.2725e-02,  7.8139e-01,  6.2422e-01,  ..., -2.6550e+00,\n",
       "           3.7356e-01, -4.9829e-01],\n",
       "         [ 7.2725e-02,  7.8139e-01,  6.2422e-01,  ..., -2.6550e+00,\n",
       "           3.7356e-01, -4.9829e-01],\n",
       "         [ 7.2725e-02,  7.8139e-01,  6.2422e-01,  ..., -2.6550e+00,\n",
       "           3.7356e-01, -4.9829e-01]]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
